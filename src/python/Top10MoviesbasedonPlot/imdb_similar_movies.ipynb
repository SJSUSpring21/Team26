{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Import 2 tables from IMDb datasets that we need\n",
    "title_basics = pd.read_csv('titlebasics.csv')\n",
    "title_ratings = pd.read_csv('title.ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only movies from the title_basics table\n",
    "movies = title_basics[(title_basics.titleType == 'movie')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the indicies for our 2 tables to the IMDb key for movies\n",
    "movies.set_index('tconst', inplace=True)\n",
    "title_ratings.set_index('tconst', inplace=True)\n",
    "# Joint the 2 tables by tconst, the IMDb key for all movies\n",
    "movies_with_rating = movies.join(title_ratings, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the top 10,000 movies, where we rank movies by the number of votes they have received\n",
    "top_10000_movies = movies_with_rating.sort_values(by='numVotes', ascending=False)[:10000]\n",
    "movies_index = top_10000_movies.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tqdm import tqdm\n",
    "#from time import sleep\n",
    "#from imdb import IMDb\n",
    "\n",
    "#ia = IMDb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keywords_dict = {}\n",
    "#for movie_index in tqdm(movies_index):\n",
    "#    sleep(1)\n",
    "#    try:\n",
    "#        keywords_dict[movie_index] = ia.get_movie_keywords(movie_index[2:])['data']['keywords']\n",
    "#    except:\n",
    "#        keywords_dict[movie_index] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keywords = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in keywords_dict.items() ])).transpose()\n",
    "#keywords = keywords.apply(lambda x: ','.join(x.dropna()), axis=1)\n",
    "#keywords = pd.DataFrame(keywords)\n",
    "#keywords.rename(columns={0:'keywords'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plots to a CSV\n",
    "#keywords.to_csv(path_or_buf='keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our keywords for the CSV\n",
    "keywords = pd.read_csv('keywords.csv')\n",
    "keywords.rename(columns={'Unnamed: 0':'tconst'}, inplace=True)\n",
    "keywords.set_index('tconst', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to our table\n",
    "movies = top_10000_movies.join(keywords, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies[movies.keywords.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.reset_index(inplace=True)\n",
    "movies = movies[['primaryTitle', 'keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Keywords\n",
    "keywords = movies['keywords'].tolist()\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "keywords = [word_tokenize(keyword.lower()) for keyword in keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_commas(doc):\n",
    "    no_commas = [t for t in doc if t!=',']\n",
    "    return(no_commas)\n",
    "\n",
    "keywords = [no_commas(kw) for kw in keywords]\n",
    "processed_keywords = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "dictionary = Dictionary(processed_keywords) # create a dictionary of words from our keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in processed_keywords] \n",
    "#create corpus where the corpus is a bag of words for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "tfidf = TfidfModel(corpus) #create tfidf model of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.similarities import MatrixSimilarity\n",
    "# Create the similarity data structure. This is the most important part where we get the similarities between the movies.\n",
    "sims = MatrixSimilarity(tfidf[corpus], num_features=len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_recommendation(movie_title, number_of_hits=10):\n",
    "    movie = movies.loc[movies.primaryTitle==movie_title] # get the movie row\n",
    "    keywords = movie['keywords'].iloc[0].split(',') #get the keywords as a Series (movie['keywords']),\n",
    "    # get just the keywords string ([0]), and then convert to a list of keywords (.split(',') )\n",
    "    query_doc = keywords #set the query_doc to the list of keywords\n",
    "    \n",
    "    query_doc_bow = dictionary.doc2bow(query_doc) # get a bag of words from the query_doc\n",
    "    query_doc_tfidf = tfidf[query_doc_bow] #convert the regular bag of words model to a tf-idf model where we have tuples\n",
    "    # of the movie ID and it's tf-idf value for the movie\n",
    "\n",
    "    similarity_array = sims[query_doc_tfidf] # get the array of similarity values between our movie and every other movie. \n",
    "    #So the length is the number of movies we have. To do this, we pass our list of tf-idf tuples to sims.\n",
    "\n",
    "    similarity_series = pd.Series(similarity_array.tolist(), index=movies.primaryTitle.values) #Convert to a Series\n",
    "    top_hits = similarity_series.sort_values(ascending=False)[1:number_of_hits+1] \n",
    "    #get the top matching results, i.e. most similar movies; start from index 1 because every movie is most similar to itself\n",
    "\n",
    "    #print the words with the highest tf-idf values for the provided movie:\n",
    "    sorted_tfidf_weights = sorted(tfidf[corpus[movie.index.values.tolist()[0]]], key=lambda w: w[1], reverse=True)\n",
    "    print('The top 5 words associated with this movie by tf-idf are: ')\n",
    "    for term_id, weight in sorted_tfidf_weights[:5]:\n",
    "        print(\" '%s' with a tf-idf score of %.3f\" %(dictionary.get(term_id), weight))\n",
    "    \n",
    "    # Print the top matching movies\n",
    "    print(\"Our top %s most similar movies for movie %s are:\" %(number_of_hits, movie_title))\n",
    "    for idx, (movie,score) in enumerate(zip(top_hits.index, top_hits)):\n",
    "        print(\"%d %s with a similarity score of %.3f\" %(idx+1, movie, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 words associated with this movie by tf-idf are: \n",
      " 'abusive-fiance' with a tf-idf score of 0.072\n",
      " 'below-decks' with a tf-idf score of 0.072\n",
      " 'berth' with a tf-idf score of 0.072\n",
      " 'blueprints' with a tf-idf score of 0.072\n",
      " 'bolts' with a tf-idf score of 0.072\n",
      "Our top 10 most similar movies for movie Titanic are:\n",
      "1 A Night to Remember with a similarity score of 0.234\n",
      "2 Poseidon with a similarity score of 0.122\n",
      "3 Titanic with a similarity score of 0.119\n",
      "4 Beyond the Poseidon Adventure with a similarity score of 0.100\n",
      "5 The Poseidon Adventure with a similarity score of 0.077\n",
      "6 The Hindenburg with a similarity score of 0.076\n",
      "7 Speed 2: Cruise Control with a similarity score of 0.073\n",
      "8 Airport '77 with a similarity score of 0.071\n",
      "9 Juggernaut with a similarity score of 0.070\n",
      "10 Godzilla with a similarity score of 0.070\n"
     ]
    }
   ],
   "source": [
    "movie_recommendation('Titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
